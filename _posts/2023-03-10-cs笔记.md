---
layout:     post
title:      "CS基础"
subtitle:   "更新中"
author:     "Alan Nam"
header-img: "img/in-post/post-bg-hello.jpg"
tags:
    - 操作系统
    - 计算机网络
    - 数据库
    - 常识

---

## 操作系统

### 进程与线程

#### 1.什么是进程？什么是线程？什么是协程？

​	我们编译的代码可执⾏⽂件只是储存在硬盘的静态⽂件，运⾏时被加载到内存，CPU执⾏内 存中指令，这个运⾏的程序被称为进程。  

​	进程是对运⾏时程序的封装，**操作系统进⾏资源调度和分配的基本单位**。

​	例如，用户运行自己的程序，系统就创建一个进程，并为它分配资源，包括各种表格、内存空间、磁盘空间、I/O设备等。然后，把该进程放入进程的就绪队列。进程调度程序选中它，为它分配CPU以及其它有关资源，该进程才真正运行。所以，进程是系统中的并发执行的单位。
​	在Mac、Windows NT等采用微内核结构的操作系统中，进程的功能发生了变化：它只是资源分配的单位，而不再是调度运行的单位。在微内核系统中，真正调度运行的基本单位是线程。因此，实现并发功能的单位是线程。
　　

​	线程是进程中执行运算的最小单位，亦即执行处理机调度的基本单位。如果把进程理解为在逻辑上操作系统所完成的任务，那么线程表示完成该任务的许多可能的子任务之一。线程可以在处理器上独立调度执行，这样，在多处理器环境下就允许几个线程各自在单独处理器上进行。操作系统提供线程就是为了方便而有效地实现这种并发性。

​	

​	协程是一种轻量级的线程，也被称为用户级线程。与操作系统线程不同，协程的调度由程序员自己控制，不需要切换上下文，因此具有比线程更低的开销和更高的并发性能。

​	协程能够在同一线程中多个任务之间进行切换，而不需要进行上下文切换。这使得协程能够在相对较少的系统资源上同时执行多个任务，从而提高系统的并发性能。协程也适用于需要长时间阻塞的操作，例如网络通信、文件读写等，可以让其他协程继续执行，从而避免了阻塞等待导致的性能损失。

#### 2.多进程和多线程的区别？

| **对比维度**   | **多进程**                                                   | **多线程**                                                   | **总结** |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| 数据共享、同步 | 数据共享复杂，需要用IPC；数据是分开的，同步简单              | 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 | 各有优势 |
| 内存、CPU      | 占用内存多，切换复杂，CPU利用率低                            | 占用内存少，切换简单，CPU利用率高                            | 线程占优 |
| 创建销毁、切换 | 创建销毁、切换复杂，速度慢                                   | 创建销毁、切换简单，速度很快                                 | 线程占优 |
| 编程、调试     | 编程简单，调试简单                                           | 编程复杂，调试复杂                                           | 进程占优 |
| 可靠性         | 进程间不会互相影响                                           | 一个线程挂掉将导致整个进程挂掉                               | 进程占优 |
| 分布式         | 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 | 适应于多核分布式                                             | 进程占优 |



#### 3.进程之间的通信方式（IPC）以及优缺点？

- 管道（PIPE）
  - 有名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信
    - 优点：可以实现任意关系的进程间的通信
    - 缺点：
      1. 长期存于系统中，使用不当容易出错
      2. 缓冲区有限
  - 无名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）
    - 优点：简单方便
    - 缺点：
      1. 局限于单向通信
      2. 只能创建在它的进程以及其有亲缘关系的进程之间
      3. 缓冲区有限

- 信号量（Semaphore）：一个计数器，可以用来控制多个线程对共享资源的访问
  - 优点：可以同步进程
  - 缺点：信号量有限

​		信号量是一个计数器,可以用来控制多个线程对共享资源的访问.,它不是用于交换大批数据,而用于多线程之间的同步.它常作为一种锁机制,防止某进程在访问资源时其它进程也访问该资源.因此,主要作为进程间以及同一个进程内不同线程之间的同步手段.



- 信号（Signal）：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生

- 消息队列（Message Queue）：是消息的链表，存放在内核中并由消息队列标识符标识
  - 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便
  - 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合

消息队列克服了信号传递信息少,管道只能承载无格式字节流以及缓冲区大小受限等特点.消息队列是UNIX下不同进程之间可实现共享资源的一种机制,UNIX允许不同进程将格式化的数据流以消息队列形式发送给任意进程.对消息队列具有操作权限的进程都可以使用msget完成对消息队列的操作控制.通过使用消息类型,进程可以按任何顺序读信息,或为消息安排优先级顺序.



- 共享内存（Shared Memory）：映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问
  - 优点：无须复制，快捷，信息量大
  - 缺点：
    1. 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
    2. 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信

共享内存是最快的IPC(进程间通信)方式,它是针对其它进程间通信方式运行效率低而专门设计的.它往往与其他通信机制,如信号量,配合使用,来实现进程间的同步与通信.



- 套接字（Socket）：可用于不同计算机间的进程通信
  - 优点：
    1. 传输数据为字节级，传输数据可自定义，数据量小效率高
    2. 传输数据时间短，性能高
    3. 适合于客户端和服务器端之间信息实时交互
    4. 可以加密,数据安全性强
  - 缺点：需对传输的数据进行解析，转化成应用级的数据。



#### 4.线程之间的通信方式？

- 锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
  - 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
  - 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。
  - 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。
  - 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制(Semaphore)
  - 无名线程信号量
  - 命名线程信号量
- 信号机制(Signal)：类似进程间的信号处理
- 屏障（barrier）：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

**线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制**

#### 5.什么时候用多线程?什么时候用多进程？

1）需要频繁创建销毁的优先用线程

原因请看上面的对比。
这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的

2）需要进行大量计算的优先使用线程

所谓大量计算，当然就是要耗费很多CPU，切换频繁了，这种情况下线程是最合适的。
这种原则最常见的是图像处理、算法处理。

3）强相关的处理用线程，弱相关的处理用进程

什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。
一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。
当然这种划分方式不是一成不变的，也可以根据实际情况进行调整。

4）可能要扩展到多机分布的用进程，多核分布的用线程

原因请看上面对比。

5）都满足需求的情况下，用你最熟悉、最拿手的方式

至于“数据共享、同步”、“编程、调试”、“可靠性”这几个维度的所谓的“复杂、简单”应该怎么取舍，我只能说：没有明确的选择方法。但我可以告诉你一个选择原则：如果多进程和多线程都能够满足要求，那么选择你最熟悉、最拿手的那个。

#### 6.进程切换为何比线程慢 

涉及到虚拟内存的问题，进程切换涉及虚拟地址空间的切换⽽线程不会。 

因为每个进程都有⾃⼰的虚拟地址空间，⽽线程是共享所在进程的虚拟地址空间的，所以同 ⼀个进程中的线程进⾏线程切换时不涉及虚拟地址空间的转换。 把虚拟地址转换为物理地址需要查找页表，页表查找是⼀个很慢的过程（⾄少访问2次内 存），因此通常使⽤Cache来缓存常⽤的地址映射，这样可以加速页表查找，这个cache就 是TLB（快表）。  

由于每个进程都有⾃⼰的虚拟地址空间，那么显然每个进程都有⾃⼰的页表，那么当进程切 换后页表也要进⾏切换，页表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟 地址转换为物理地址就会变慢，表现出来的就是程序运⾏会变慢，⽽线程切换则不会导致 TLB失效，因为线程线程⽆需切换地址空间，这也就是进程切换要⽐同进程下线程切换慢的 原因。

#### 并发与并行

（1）单个核⼼在很短时间内分别执⾏多个进程，称为并发 

（2）多个核⼼同时执⾏多个进程称为并⾏ 

（3）对于并发来说，CPU需要从⼀个进程切换到另⼀个进程，这个过程需要保存进程的状 态信息

### 内存、堆、栈

#### 进程的地址空间分布

![image-20230403231319668](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230403231319668.png)

（1）命令⾏参数和环境变量 命令⾏参数是指从命令⾏执⾏程序的时候，给程序的参数。  

（2）栈区 存储局部变量、函数参数值。栈从⾼地址向低地址增长。是⼀块连续的空间。  

（3）⽂件映射区 位于堆和栈之间。  

（4）堆区 动态申请内存⽤。堆从低地址向⾼地址增长。  

（5）BSS 段 存放程序中未初始化的 全局变量和静态变量 的⼀块内存区域。  

（6）数据段 存放程序中已初始化的 全局变量和静态变量 的⼀块内存区域。

（7）代码段 存放程序执⾏代码的⼀块内存区域。只读，代码段的头部还会包含⼀些只读的常数变量。

#### 说⼀说C与C++的内存分配⽅式 

（1）从静态存储区域分配 

内存在程序编译的时候就已经分配好，这块内存在程序的整个运⾏期间都存在，如全局变量，static变量。 

（2）在栈上创建 

在执⾏函数时，函数内局部变量的存储单元都可以在栈上创建，函数执⾏结束时这些存储单 元⾃动被释放。栈内存分配运算内置于处理器的指令集中，效率很⾼，但是分配的内存容量有限。 

（3）从堆上分配(动态内存分配)

程序在运⾏的时候⽤malloc或new申请任意多少的内存，程序员负责在何时⽤free或delete 释放内存。动态内存的⽣存期⾃⼰决定，使⽤⾮常灵活。

#### C++堆和栈内存比较

1.当我们的程序开始的时候，程序被分成了一堆不同的内存区域，除了堆和栈以外，还有很多东西，但我们最关心这两个 。

2.**栈**通常是一个预定义大小的内存区域，通常约为2兆字节左右。**堆**也是一个预定义了默认值的区域，**但是它可以**随着应用程序的进行而改变。

3.**栈和堆内存区域的实际位置（物理位置）在ram中完全一样**（并不是一个存在CPU缓存而另一个存在其他地方）

> 在程序中，内存是用来实际储存数据的。我们需要一个地方来储存允许程序所需要的数据（比如局部变量or从文件中读取的东西）。而栈和堆，它们就是可以储存数据的地方，但**栈和堆的工作原理非常非常不同**，但本质上它们做的事情是一样的

4.栈和堆的区别

区别一：定义格式不同

```cpp
//在栈上分配
int val = 5; 
//在堆上分配
int *hval = new int;    //区别是，我们需要用new关键词来在堆上分配
*hval = 5;
```

区别二：内存分配方式不同

对栈来说：

> **在栈上**，分配的内存都是**连续**的。添加一个int，则**栈指针（栈顶部的指针）**就移动4个字节，所以连续分配的数据在内存上都是**连续**的。栈分配数据是直接把数据堆在一起（所做的就是移动栈指针），所以栈分配数据会很快 。
> 如果离开作用域，在栈中分配的所有内存都会弹出，内存被释放。

对堆来说

> **在堆上**，分配的内存都是**不连续**的，`new`实际上做的是在内存块的**空闲列表**中找到空闲的内存块，然后把它用一个指针圈起来，然后返回这个指针。（但如果**空闲列表**找不到合适的内存块，则会询问**操作系统**索要更多内存，而这种操作是很麻烦的，潜在成本是巨大的）
> 离开作用域后，堆中的内存仍然存在

建议： **能在栈上分配就在栈上分配**，**不能够在栈上分配时或者有特殊需求时（比如需要生存周期比函数作用域更长，或者需要分配一些大的数据），才在堆上分配**

### 死锁

**原因**

- 系统资源不足
- 资源分配不当
- 进程运行推进顺序不合适

**产生条件**

- 互斥
- 请求和保持
- 不剥夺
- 环路

**预防**

- 打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造。
- 打破不可抢占条件：当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。
- 打破占有且申请条件：采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。
- 打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源。
- 有序资源分配法
- 银行家算法

### 文件系统

- Windows：FCB 表 + FAT + 位图
- Unix：inode + 混合索引 + 成组链接

### 主机字节序与网络字节序

#### **主机字节序**

主机字节序又叫 CPU 字节序，其不是由操作系统决定的，而是由 CPU 指令集架构决定的。主机字节序分为两种：

- 大端字节序（Big Endian）：高序字节存储在低位地址，低序字节存储在高位地址
- 小端字节序（Little Endian）：高序字节存储在高位地址，低序字节存储在低位地址

**存储方式**

32 位整数 `0x12345678` 是从起始位置为 `0x00` 的地址开始存放，则：

| 内存地址 | 0x00 | 0x01 | 0x02 | 0x03 |
| -------- | ---- | ---- | ---- | ---- |
| 大端     | 12   | 34   | 56   | 78   |
| 小端     | 78   | 56   | 34   | 12   |

大端小端图片

![大端序](https://gitee.com/huihut/interview/raw/master/images/CPU-Big-Endian.svg.png) ![小端序](https://gitee.com/huihut/interview/raw/master/images/CPU-Little-Endian.svg.png)

##### 判断大端小端

可以这样判断自己 CPU 字节序是大端还是小端：

```cpp
#include <iostream>
using namespace std;

int main()
{
    int i = 0x12345678;

    if (*((char*)&i) == 0x12)
        cout << "大端" << endl;
    else    
        cout << "小端" << endl;

    return 0;
}
```

##### 各架构处理器的字节序

- x86（Intel、AMD）、MOS Technology 6502、Z80、VAX、PDP-11 等处理器为小端序；
- Motorola 6800、Motorola 68000、PowerPC 970、System/370、SPARC（除 V9 外）等处理器为大端序；
- ARM（默认小端序）、PowerPC（除 PowerPC 970 外）、DEC Alpha、SPARC V9、MIPS、PA-RISC 及 IA64 的字节序是可配置的。

#### 网络字节序

网络字节顺序是 TCP/IP 中规定好的一种数据表示格式，它与具体的 CPU 类型、操作系统等无关，从而可以保证数据在不同主机之间传输时能够被正确解释。

网络字节顺序采用：大端（Big Endian）排列方式。

### 页面置换算法

在地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。

**分类**

- 全局置换：在整个内存空间置换
- 局部置换：在本进程中进行置换

**算法**

全局：

- 工作集算法
- 缺页率置换算法

局部：

- 最佳置换算法（OPT）
- 先进先出置换算法（FIFO）
- 最近最久未使用（LRU）算法
- 时钟（Clock）置换算法

#### 手撕LRU

以下是基于 双向链表 + HashMap 的 LRU 算法实现，对算法的解释如下：

- 访问某个节点时，将其从原来的位置删除，并重新插入到链表头部。这样就能保证链表尾部存储的就是最近最久未使用的节点，当节点数量大于缓存最大空间时就淘汰链表尾部的节点。
- 为了使删除操作时间复杂度为 O(1)，就不能采用遍历的方式找到某个节点。HashMap 存储着 Key 到节点的映射，通过 Key 就能以 O(1) 的时间得到节点，然后再以 O(1) 的时间将其从双向队列中删除。

```c++
#include <cstddef>
#include <list>
#include <stdexcept>
#include <unordered_map>

namespace cache {

template <typename key_t, typename value_t> class lru_cache {
public:
  typedef typename std::pair<key_t, value_t> key_value_pair_t;
  typedef typename std::list<key_value_pair_t>::iterator list_iterator_t;

  lru_cache(size_t max_size) : _max_size(max_size) {}

  void put(const key_t &key, const value_t &value) {
    auto it = _cache_items_map.find(key);
    _cache_items_list.push_front(key_value_pair_t(key, value));
    if (it != _cache_items_map.end()) {
      _cache_items_list.erase(it->second);
      _cache_items_map.erase(it);
    }
    _cache_items_map[key] = _cache_items_list.begin();

    if (_cache_items_map.size() > _max_size) {
      auto last = _cache_items_list.end();
      last--;
      _cache_items_map.erase(last->first);
      _cache_items_list.pop_back();
    }
  }

  const value_t &get(const key_t &key) {
    auto it = _cache_items_map.find(key);
    if (it == _cache_items_map.end()) {
      throw std::range_error("There is no such key in cache");
    } else {
      _cache_items_list.splice(_cache_items_list.begin(), _cache_items_list,
                               it->second);
      return it->second->second;
    }
  }

  bool exists(const key_t &key) const {
    return _cache_items_map.find(key) != _cache_items_map.end();
  }

  size_t size() const { return _cache_items_map.size(); }

private:
  std::list<key_value_pair_t> _cache_items_list;
  std::unordered_map<key_t, list_iterator_t> _cache_items_map;
  size_t _max_size;
};
```

## 计算机网络

计算机网络体系结构：

![计算机网络体系结构](https://gitee.com/huihut/interview/raw/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png)

#### 各层作用及协议

| 分层       | 作用                                                | 协议                                                |
| ---------- | --------------------------------------------------- | --------------------------------------------------- |
| 物理层     | 通过媒介传输比特，确定机械及电气规范（比特 Bit）    | RJ45、CLOCK、IEEE802.3（中继器，集线器）            |
| 数据链路层 | 将比特组装成帧和点到点的传递（帧 Frame）            | PPP、FR、HDLC、VLAN、MAC（网桥，交换机）            |
| 网络层     | 负责数据包从源到宿的传递和网际互连（包 Packet）     | IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP（路由器） |
| 运输层     | 提供端到端的可靠报文传递和错误恢复（ 段Segment）    | TCP、UDP、SPX                                       |
| 会话层     | 建立、管理和终止会话（会话协议数据单元 SPDU）       | NFS、SQL、NETBIOS、RPC                              |
| 表示层     | 对数据进行翻译、加密和压缩（表示协议数据单元 PPDU） | JPEG、MPEG、ASII                                    |
| 应用层     | 允许访问OSI环境的手段（应用协议数据单元 APDU）      | FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS              |



#### 路由表包含什么？

1. 网络 ID（Network ID, Network number）：就是目标地址的网络 ID。
2. 子网掩码（subnet mask）：用来判断 IP 所属网络
3. 下一跳地址/接口（Next hop / interface）：就是数据在发送到目标地址的旅途中下一站的地址。其中 interface 指向 next hop（即为下一个 route）。一个自治系统（AS, Autonomous system）中的 route 应该包含区域内所有的子网络，而默认网关（Network id: `0.0.0.0`, Netmask: `0.0.0.0`）指向自治系统的出口。

根据应用和执行的不同，路由表可能含有如下附加信息：

1. 花费（Cost）：就是数据发送过程中通过路径所需要的花费。
2. 路由的服务质量
3. 路由中需要过滤的出/入连接列表

### TCP/UDP

#### TCP 与 UDP 的区别

1. TCP 面向连接，UDP 是无连接的；
2. TCP 提供可靠的服务，也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付
3. TCP 的逻辑通信信道是全双工的可靠信道；UDP 则是不可靠信道
4. 每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信
5. TCP 面向字节流（可能出现黏包问题），实际上是 TCP 把数据看成一连串无结构的字节流；UDP 是面向报文的（不会出现黏包问题）
6. UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等）
7. TCP 首部开销20字节；UDP 的首部开销小，只有 8 个字节
8. 分⽚⽅式 。 TCP数据⼤于MSS时会在TCP层将数据进⾏分⽚传输，到达⽬的地后同样在传输层进⾏合 并，如果有某个⽚丢失则只需要重传丢失的分⽚即可; UDP数据⼤于MTU时会在IP层分⽚，同样也在⽬的IP层合并，如果某个IP分⽚丢失，则需要 将所有分⽚都进⾏重传，开销⼤。

#### TCP 黏包问题

**原因**

TCP 是一个基于字节流的传输服务（UDP 基于报文的），“流” 意味着 TCP 所传输的数据是没有边界的。所以可能会出现两个数据包黏在一起的情况。

**解决**

- 发送定长包。如果每个消息的大小都是一样的，那么在接收对等方只要累计接收数据，直到数据等于一个定长的数值就将它作为一个消息。
- 包头加上包体长度。包头是定长的 4 个字节，说明了包体的长度。接收对等方先接收包头长度，依据包头长度来接收包体。
- 在数据包之间设置边界，如添加特殊符号 `\r\n` 标记。FTP 协议正是这么做的。但问题在于如果数据正文中也含有 `\r\n`，则会误判为消息的边界。
- 使用更加复杂的应用层协议。

#### TCP 流量控制

**概念**

流量控制（flow control）就是让发送方的发送速率不要太快，要让接收方来得及接收。

**方法**

利用可变窗口进行流量控制

![img](https://gitee.com/huihut/interview/raw/master/images/%E5%88%A9%E7%94%A8%E5%8F%AF%E5%8F%98%E7%AA%97%E5%8F%A3%E8%BF%9B%E8%A1%8C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E4%B8%BE%E4%BE%8B.png)

#### TCP 拥塞控制

**概念**

拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。

**方法**

- 慢开始( slow-start )
- 拥塞避免( congestion avoidance )
- 快重传( fast retransmit )
- 快恢复( fast recovery )

#### TCP 传输连接管理

##### TCP 三次握手建立连接

![UDP 报文](https://gitee.com/huihut/interview/raw/master/images/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5.png)

【TCP 建立连接全过程解释】

1. 客户端发送 SYN 给服务器，说明客户端请求建立连接；
2. 服务端收到客户端发的 SYN，并回复 SYN+ACK 给客户端（同意建立连接）；
3. 客户端收到服务端的 SYN+ACK 后，回复 ACK 给服务端（表示客户端收到了服务端发的同意报文）；
4. 服务端收到客户端的 ACK，连接已建立，可以数据传输。

##### TCP 为什么要进行三次握手？

1、阻⽌重复历史连接的初始化（主因） 

- 当旧的SYN报⽂先到达服务端，服务端回⼀个ACK+SYN报⽂ 
- 客户端收到后可以根据⾃⾝的上下⽂，判断这是⼀个历史连接（序列号过期或超 时），那么客户端就会发送 RST 报⽂给服务端，表⽰中⽌这⼀次连接。 

两次握⼿在收到服务端的响应后开始发⽣数据，不能判断当前连接是否是历史连接。 

三次握⼿可以在客户端准备发送第三次报⽂时，客户端因有⾜够的上下⽂来判断当前连接是 否是历史连接。

(或者是说为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。)

2、**同步双⽅的初始序列号**  因为双方都需要确认对方收到了自己发送的序列号，确认过程最少要进行三次通信。

TCP 协议的通信双⽅， 都必须维护⼀个「序列号」， 序列号是可靠传输的⼀个关键因素。 

- 接收端可以去除重复数据。 
- 接收端可以按照序列号顺序接收。 
- 标识发送的数据包，哪些已经被收到。 

过程 

1. 客户端发送第⼀个报⽂，携带客户端初始序列号的SYN报⽂。 
2. 服务器发送第⼆个报⽂，携带服务器初始序列号的ACK + SYN的应答报⽂，表⽰收 到客户端的SYN报⽂。 
3. 客户端发送第三个报⽂，携带服务器的ACK应答报⽂。 

这样⼀来⼀回，才能确保双⽅的初始序列号能被可靠的同步。

两次握⼿只保证了⼀⽅的初始序列号能被对⽅成功接收，没办法保证双⽅的初始序列号都能 被确认接收。

3、避免资源浪费。 

- 两次握⼿会造成消息滞留情况下，服务器重复接受⽆⽤的连接请求 SYN 报⽂，⽽ 造成重复分配资源。 
- 只有两次握⼿时，如果客户端的SYN请求连接在⽹络中阻塞，客户端没有收到服务 端的ACK报⽂，会重新发送SYN。 
- 由于没有第三次握⼿，服务器不清楚客户端是否收到了⾃⼰发送的建⽴连接的 ACK 确认信号，所以每收到⼀个 SYN 就只能先主动建⽴⼀个连接。

因为信道不可靠，而 TCP 想在不可靠信道上建立可靠地传输，那么三次通信是理论上的最小值。（而 UDP 则不需建立可靠传输，因此 UDP 不需要三次握手。）







**补充**

**第一个包，即A发给B的SYN 中途被丢，没有到达B**

A会周期性超时重传，直到收到B的确认

**第二个包，即B发给A的SYN +ACK 中途被丢，没有到达A**

B会周期性超时重传，直到收到A的确认

**第三个包，即A发给B的ACK 中途被丢，没有到达B**
A不会超时重传这个ACK。**TCP不会为没有数据的ACK超时重传**。

那该如何是好？**B如果没有收到A的ACK，会超时重传自己的SYN同步信号，一直到收到A的ACK为止。**



A发完ACK，单方面认为TCP为 Established状态，而B显然认为TCP为Active状态：

a. 假定此时双方都没有数据发送，B会周期性超时重传，直到收到A的确认，收到之后B的TCP 连接也为 Established状态，双向可以发包。

b. 假定此时A有数据发送，B收到A的 Data + ACK，自然会切换为established 状态，并接受A的 Data。

c. 假定B有数据发送，数据发送不了，会一直周期性超时重传SYN + ACK，直到收到A的确认才可以发送数据。



##### TCP 四次挥手释放连接

![UDP 报文](https://gitee.com/huihut/interview/raw/master/images/TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E9%87%8A%E6%94%BE%E8%BF%9E%E6%8E%A5.png)

【TCP 释放连接全过程解释】

1. 客户端发送 FIN 给服务器，说明客户端不必发送数据给服务器了（请求释放从客户端到服务器的连接）；
2. 服务器接收到客户端发的 FIN，并回复 ACK 给客户端（同意释放从客户端到服务器的连接）；
3. 客户端收到服务端回复的 ACK，此时从客户端到服务器的连接已释放（但服务端到客户端的连接还未释放，并且客户端还可以接收数据）；
4. 服务端继续发送之前没发完的数据给客户端；
5. 服务端发送 FIN+ACK 给客户端，说明服务端发送完了数据（请求释放从服务端到客户端的连接，就算没收到客户端的回复，过段时间也会自动释放）；
6. 客户端收到服务端的 FIN+ACK，并回复 ACK 给服务端（同意释放从服务端到客户端的连接）；
7. 服务端收到客户端的 ACK 后，释放从服务端到客户端的连接。
8. 客户端在经过 2MSL ⼀段时间后，⾃动进⼊close状态，客户端也完成连接的关 闭。

##### TCP 为什么要进行四次挥手？

**【问题一】**TCP 为什么要进行四次挥手？ / 为什么 TCP 建立连接需要三次，而释放连接则需要四次？

因为 TCP 是全双工模式，客户端请求关闭连接后，客户端向服务端的连接关闭（一二次挥手），服务端继续传输之前没传完的数据给客户端（数据传输），服务端向客户端的连接关闭（三四次挥手）。所以 TCP 释放连接时**服务器的 ACK 和 FIN 是分开发送**的（中间隔着数据传输），而 TCP 建立连接时服务器的 ACK 和 SYN 是一起发送的（第二次握手），所以 TCP 建立连接需要三次，而释放连接则需要四次。

**【问题二】**为什么 TCP 连接时可以 ACK 和 SYN 一起发送，而释放时则 ACK 和 FIN 分开发送呢？（ACK 和 FIN 分开是指第二次和第三次挥手）

因为客户端请求释放时，服务器可能还有数据需要传输给客户端，因此服务端要先响应客户端 FIN 请求（服务端发送 ACK），然后数据传输，传输完成后，服务端再提出 FIN 请求（服务端发送 FIN）；而连接时则没有中间的数据传输，因此连接时可以 ACK 和 SYN 一起发送。

**【问题三】**为什么客户端释放最后需要 TIME-WAIT 等待 2MSL 呢？

`MSL是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上 存在的最长时间，超过这个时间报⽂将被丢弃。`

1. 为了保证客户端发送的最后一个 ACK 报文能够到达服务端。若未成功到达，则服务端超时重传 FIN+ACK 报文段，客户端再重传 ACK，并重新计时。
2. 防止已失效的连接请求报文段出现在本连接中。TIME-WAIT 持续 2MSL 可使本连接持续的时间内所产生的所有报文段都从网络中消失，这样可使下次连接中不会出现旧的连接报文段。
3. ⽹络中可能存在发送⽅的数据包，当这些发送⽅的数据包被接收⽅ 处理后又会向对⽅发送响应，所以⼀来⼀回需要等待 2 倍的时间。

**【问题四】**为什么需要 TIME_WAIT 状态？

主动发起关闭连接的⼀⽅，才会有 TIME-WAIT 状态。 

需要 TIME-WAIT 状态，主要是两个原因： 

1. 防⽌具有相同「四元组」的「旧」数据包被收到  
2. 保证「被动关闭连接」的⼀⽅能被正确的关闭，即保证最后的 ACK 能让被动关闭⽅接收，从⽽帮助其正常关闭  

有相同端口的 TCP 连接被复⽤后，被延迟的相同四元组的数据包抵达了客户端，那么客户 端是有可能正常接收这个过期的报⽂，这就会产⽣数据错乱等严重的问题。  

经过 2MSL 这个时间，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络 中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产⽣的。 

最后的ACK如果丢失，客户端直接进⼊close，服务端⼀直在等待ACK状态。当客户端发起 建⽴连接的SYN请求，服务端会发送RST报⽂回应，连接建⽴会关闭。  

如果 TIME-WAIT 等待⾜够长的情况就会遇到两种情况：

1. 服务端正常收到四次挥⼿的最后⼀个 ACK 报⽂，则服务端正常关闭连接。 
2. 服务端没有收到四次挥⼿的最后⼀个 ACK 报⽂时，则会重发 FIN 关闭连接报⽂并 等待新的 ACK 报⽂。



**【问题五】**TIME_WAIT 过多有什么危害？ 

过多的TIME-WAIT 状态主要的危害有两种：

1. 内存资源占⽤；  
2. 对端口资源的占⽤，⼀个 TCP 连接⾄少消耗⼀个本地端口； 

 如果发起连接⼀⽅的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致⽆法创建新连接

### HTTP/HTTPS

特性：简单、灵活、易于扩展、应⽤⼴泛和跨平台。  简述： Web 上的通信都是建⽴在 HTTP 协议上的  1. 客户端发起 HTTP 请求； 2. 服务器做出响应处理后，返回 HTTP 响应报⽂

##### WWW

- WWW（World Wide Web，环球信息网，万维网）是一个由许多互相链接的超文本组成的系统，通过互联网访问

www构建技术

1. HTML (HyperText Markup Language)：作为页⾯的⽂本标记语⾔ 
2. HTTP (HyperText Transfer Protocol)：⽂档传递协议； 
3. URL (Uniform Resource Locator)：指定⽂档所在地址

##### URL

- URL（Uniform Resource Locator，统一资源定位符）是因特网上标准的资源的地址（Address）

标准格式：

- `协议类型:[//服务器地址[:端口号]][/资源层级UNIX文件路径]文件名[?查询][#片段ID]`

  完整格式：

- `协议类型:[//[访问资源需要的凭证信息@]服务器地址[:端口号]][/资源层级UNIX文件路径]文件名[?查询][#片段ID]`

> 其中【访问凭证信息@；:端口号；?查询；#片段ID】都属于选填项
> 如：`https://github.com/huihut/interview#cc`



#### HTTP

HTTP（HyperText Transfer Protocol，超文本传输协议）是一种用于分布式、协作式和超媒体信息系统的应用层协议。HTTP 是万维网的数据通信的基础。

1. 1996 年的 5 ⽉，HTTP/1.0，并记载于 RFC1945。现在 HTTP/1.0，仍然被使⽤在 服务器端；
2. 1997 年 1 ⽉，发布 HTTP/1.1 ，是⽬前主流的 HTTP 协议版本 
3. 现今，HTTP/2.0 正在制订中，但还未得到⼴泛的使⽤

###### 特点

**简单** 

基本报⽂格式为header+body，头部信息也是key-value简单⽂本的形式，易于理解。 

**灵活和易于扩展** 

- HTTP协议⾥的各种请求⽅法、URI/URL、状态码、头字段等每个组成要求都没有 被固定死，都允许开发⼈员⾃定义和扩充;  
- HTTP⼯作在应⽤层（OSI第七层），下层可以随意变化;  
- HTTPS就是在HTTP与TCP之间增加了SSL/TSL安全传输层，HTTP/3把TCP换成了 基于UDP的QUIC。  

**⽆状态、明⽂传输、不安全** 

1、⽆状态：  服务器不会去记忆HTTP的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器 的负担。但它在完成有关联性的操作时会⾮常⿇烦。  

2、明⽂传输： 传输过程中的信息，是可⽅便阅读的，通过浏览器的F12控制台或Wireshark抓包都可以直 接⾁眼查看  为我们调试⼯作带来了极⼤的便利性，但信息透明，容易被窃取。  

3、不安全：  1. 通信使⽤明⽂（不加密），内容可能被窃听 2. 不验证通信⽅的⾝份，因此有可能遭遇伪装 3. ⽆法证明报⽂的完整性，所以有可能已遭篡改 

可以⽤ HTTPS 的⽅式解决，也就是通过引⼊ SSL/TLS 层，使得在安全上达到了极致。

###### 请求方法

| 方法    | 意义                                                         |
| ------- | ------------------------------------------------------------ |
| OPTIONS | 请求一些选项信息，允许客户端查看服务器的性能                 |
| GET     | 请求指定的页面信息，并返回实体主体                           |
| HEAD    | 类似于 get 请求，只不过返回的响应中没有具体的内容，用于获取报头 |
| POST    | 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改 |
| PUT     | 从客户端向服务器传送的数据取代指定的文档的内容               |
| DELETE  | 请求服务器删除指定的页面                                     |
| TRACE   | 回显服务器收到的请求，主要用于测试或诊断                     |

###### 状态码（Status-Code）

- 1xx：表示通知信息，如请求收到了或正在进行处理
  - 100 Continue：继续，客户端应继续其请求
  - 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议
- 2xx：表示成功，如接收或知道了
  - 200 OK: 请求成功
- 3xx：表示重定向，如要完成请求还必须采取进一步的行动
  - 301 Moved Permanently: 永久移动。请求的资源已被永久的移动到新 URL，返回信息会包括新的 URL，浏览器会自动定向到新 URL。今后任何新的请求都应使用新的 URL 代替
- 4xx：表示客户的差错，如请求中有错误的语法或不能完成
  - 400 Bad Request: 客户端请求的语法错误，服务器无法理解
  - 401 Unauthorized: 请求要求用户的身份认证
  - 403 Forbidden: 服务器理解请求客户端的请求，但是拒绝执行此请求（权限不够）
  - 404 Not Found: 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置 “您所请求的资源无法找到” 的个性页面
  - 408 Request Timeout: 服务器等待客户端发送的请求时间过长，超时
- 5xx：表示服务器的差错，如服务器失效无法完成请求
  - 500 Internal Server Error: 服务器内部错误，无法完成请求
  - 503 Service Unavailable: 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的 Retry-After 头信息中
  - 504 Gateway Timeout: 充当网关或代理的服务器，未及时从远端服务器获取请求



#### DNS

（1）概念 

1. DNS协议⽤来将域名转换为IP地址，也可将IP地址转换为相应的域名地址 
2. DNS：⾯向⽤户 IP：⾯向主机 
3. 域名服务主要是基于UDP实现的，服务器端口号为53 

（2）解析过程 

浏览器查询URL对应IP：浏览器缓存→操作系统缓存→路由器缓存; 

三种类型的DNS服务器：根DNS服务器、顶级域DNS服务器、权威DNS服务器;  

1. 浏览器检查浏览器⾃⾝的DNS缓存中，是否有域名对应的DNS缓存 
2.  查看系统的hosts⽂件（C:\Windows\System32\drivers\etc）是否有域名对应的IP 地址 
3. 浏览器发起DNS系统调⽤，向本地配置的⾸选DNS服务器发起域名解析请求（通过 UDP协议，向DNS的53端口发起请求） 
4. ⾸先，请求会在运营商DNS服务器（本地服务器）上进⾏请求，若找到对应的条 ⽬，且没有过期，则解析成功；否则，进⼊5 
5. 运营商DNS服务器，根据解析请求，迭代查询，⾸先找到根域名服务器IP地址，然 后找到根域的DNS地址，发送请求 
6. 根域服务器收到请求后，根据域名，返回对应的顶级域服务器IP地址，并返回给运 营商DNS服务器 
7. 运营商DNS服务器收到根域名服务器传回来的顶级域名服务器IP地址后，向顶级域 名服务器发送请求 
8. 顶级域名服务器收到请求后，返回该域名对应的权威域名服务器IP地址，并返回给 运营商DNS服务器 
9. 运营商DNS服务器获得权威域名服务器的响应信息后，返回给请求的主机，DNS解 析完成 

DNS主要通过UDP通信，报⽂结构分为头部header、查询部分qurestion、应答部分 answer/authority/addition

![image-20230405003440397](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230405003440397.png)



### Web 页面请求过程

#### 1. DHCP 配置主机信息

- 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。
- 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。
- 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。
- 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:FF，将广播到与交换机连接的所有设备。
- 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。
- 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。
- 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。

#### 2. ARP 解析 MAC 地址

- 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。
- 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。
- 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。
- 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。
- DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。
- 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。
- 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。

#### 3. DNS 解析域名

- 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。
- 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。
- 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。
- 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。
- 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。

#### 4. HTTP 请求页面

- 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。
- 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。
- HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。
- 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。
- HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。
- 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。

#### 网络编程

##### Socket

> [Linux Socket 编程（不限 Linux）](https://www.cnblogs.com/skynet/archive/2010/12/12/1903949.html)
>
> [UDP 通信流程_udp通信_艾米莉亚糖的博客-CSDN博客](https://blog.csdn.net/Superman___007/article/details/125833364)

![Socket 客户端服务器通讯](https://gitee.com/huihut/interview/raw/master/images/socket%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%9A%E8%AE%AF.jpg)



udp 是一个面向无连接的，不安全的，报式传输层协议，udp 的通信过程默认也是阻塞的。

- UDP通信不需要建立连接 ，因此不需要进行 connect () 操作
- UDP通信过程中，每次都需要指定数据接收端的IP和端口，和发快递差不多
- UDP不对收到的数据进行排序，在UDP报文的首部中并没有关于数据顺序的信息
- UDP对接收到的数据报不回复确认信息，发送端不知道数据是否被正确接收，也不会重发数据。
- 如果发生了数据丢失，不存在丢一半的情况，如果丢当前这个数据包就全部丢失了

**通信流程**

使用 UDP 进行通信，服务器和客户端的处理步骤比 TCP 要简单很多，并且两端是对等的 （通信的处理流程几乎是一样的），也就是说并没有严格意义上的客户端和服务器端。UDP 的通信流程如下：

![img](https://img-blog.csdnimg.cn/62ef5a0cc8084169bac41b57dc0b84fa.jpeg)

## 数据库

### 基本概念

- 数据（data）：描述事物的符号记录称为数据。
- 数据库（DataBase，DB）：是长期存储在计算机内、有组织的、可共享的大量数据的集合，具有永久存储、有组织、可共享三个基本特点。
- 数据库管理系统（DataBase Management System，DBMS）：是位于用户与操作系统之间的一层数据管理软件。
- 数据库系统（DataBase System，DBS）：是有数据库、数据库管理系统（及其应用开发工具）、应用程序和数据库管理员（DataBase Administrator DBA）组成的存储、管理、处理和维护数据的系统。
- 实体（entity）：客观存在并可相互区别的事物称为实体。
- 属性（attribute）：实体所具有的某一特性称为属性。
- 码（key）：唯一标识实体的属性集称为码。
- 实体型（entity type）：用实体名及其属性名集合来抽象和刻画同类实体，称为实体型。
- 实体集（entity set）：同一实体型的集合称为实体集。
- 联系（relationship）：实体之间的联系通常是指不同实体集之间的联系。
- 模式（schema）：模式也称逻辑模式，是数据库全体数据的逻辑结构和特征的描述，是所有用户的公共数据视图。
- 外模式（external schema）：外模式也称子模式（subschema）或用户模式，它是数据库用户（包括应用程序员和最终用户）能够看见和使用的局部数据的逻辑结构和特征的描述，是数据库用户的数据视图，是与某一应用有关的数据的逻辑表示。
- 内模式（internal schema）：内模式也称为存储模式（storage schema），一个数据库只有一个内模式。他是数据物理结构和存储方式的描述，是数据库在数据库内部的组织方式。

### 常用数据模型

- 层次模型（hierarchical model）
- 网状模型（network model）
- 关系模型（relational model）
  - 关系（relation）：一个关系对应通常说的一张表
  - 元组（tuple）：表中的一行即为一个元组
  - 属性（attribute）：表中的一列即为一个属性
  - 码（key）：表中可以唯一确定一个元组的某个属性组
  - 域（domain）：一组具有相同数据类型的值的集合
  - 分量：元组中的一个属性值
  - 关系模式：对关系的描述，一般表示为 `关系名(属性1, 属性2, ..., 属性n)`
- 面向对象数据模型（object oriented data model）
- 对象关系数据模型（object relational data model）
- 半结构化数据模型（semistructure data model）

### 常用 SQL 操作

| 对象类型   | 对象                                                         | 操作类型                                                     |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 数据库模式 | 模式                                                         | `CREATE SCHEMA`                                              |
| 基本表     | `CREATE SCHEMA`，`ALTER TABLE`                               |                                                              |
| 视图       | `CREATE VIEW`                                                |                                                              |
| 索引       | `CREATE INDEX`                                               |                                                              |
| 数据       | 基本表和视图                                                 | `SELECT`，`INSERT`，`UPDATE`，`DELETE`，`REFERENCES`，`ALL PRIVILEGES` |
| 属性列     | `SELECT`，`INSERT`，`UPDATE`，`REFERENCES`，`ALL PRIVILEGES` |                                                              |

> SQL 语法教程：[runoob . SQL 教程](http://www.runoob.com/sql/sql-tutorial.html)

### 关系型数据库

- 基本关系操作：查询（选择、投影、连接（等值连接、自然连接、外连接（左外连接、右外连接））、除、并、差、交、笛卡尔积等）、插入、删除、修改
- 关系模型中的三类完整性约束：实体完整性、参照完整性、用户定义的完整性

#### 索引

- 数据库索引：顺序索引、B+ 树索引、hash 索引
- [MySQL 索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

### 数据库完整性

- 数据库的完整性是指数据的正确性和相容性。
  - 完整性：为了防止数据库中存在不符合语义（不正确）的数据。
  - 安全性：为了保护数据库防止恶意破坏和非法存取。
- 触发器：是用户定义在关系表中的一类由事件驱动的特殊过程。

### 关系数据理论

- 数据依赖是一个关系内部属性与属性之间的一种约束关系，是通过属性间值的相等与否体现出来的数据间相关联系。
- 最重要的数据依赖：函数依赖、多值依赖。

#### 范式

- 第一范式（1NF）：属性（字段）是最小单位不可再分。
- 第二范式（2NF）：满足 1NF，每个非主属性完全依赖于主键（消除 1NF 非主属性对码的部分函数依赖）。
- 第三范式（3NF）：满足 2NF，任何非主属性不依赖于其他非主属性（消除 2NF 非主属性对码的传递函数依赖）。
- 鲍依斯-科得范式（BCNF）：满足 3NF，任何非主属性不能对主键子集依赖（消除 3NF 主属性对码的部分和传递函数依赖）。
- 第四范式（4NF）：满足 3NF，属性之间不能有非平凡且非函数依赖的多值依赖（消除 3NF 非平凡且非函数依赖的多值依赖）。

### 数据库恢复

- 事务：是用户定义的一个数据库操作序列，这些操作要么全做，要么全不做，是一个不可分割的工作单位。
- 事物的 ACID 特性：原子性、一致性、隔离性、持续性。
- 恢复的实现技术：建立冗余数据 -> 利用冗余数据实施数据库恢复。
- 建立冗余数据常用技术：数据转储（动态海量转储、动态增量转储、静态海量转储、静态增量转储）、登记日志文件。

### 并发控制

- 事务是并发控制的基本单位。
- 并发操作带来的数据不一致性包括：丢失修改、不可重复读、读 “脏” 数据。
- 并发控制主要技术：封锁、时间戳、乐观控制法、多版本并发控制等。
- 基本封锁类型：排他锁（X 锁 / 写锁）、共享锁（S 锁 / 读锁）。
- 活锁死锁：
  - 活锁：事务永远处于等待状态，可通过先来先服务的策略避免。
  - 死锁：事务永远不能结束
    - 预防：一次封锁法、顺序封锁法；
    - 诊断：超时法、等待图法；
    - 解除：撤销处理死锁代价最小的事务，并释放此事务的所有的锁，使其他事务得以继续运行下去。
- 可串行化调度：多个事务的并发执行是正确的，当且仅当其结果与按某一次序串行地执行这些事务时的结果相同。可串行性时并发事务正确调度的准则。

## 设计模式



## 其他

### 链接装载库

> 本节部分知识点来自《程序员的自我修养——链接装载库》

#### 各平台文件格式

| 平台       | 可执行文件 | 目标文件 | 动态库/共享对象       | 静态库       |
| ---------- | ---------- | -------- | --------------------- | ------------ |
| Windows    | exe        | obj      | dll                   | lib          |
| Unix/Linux | ELF、out   | o        | so                    | a            |
| Mac        | Mach-O     | o        | dylib、tbd、framework | a、framework |

#### 编译链接过程

1. 预编译（预编译器处理如 `#include`、`#define` 等预编译指令，生成 `.i` 或 `.ii` 文件）
2. 编译（编译器进行词法分析、语法分析、语义分析、中间代码生成、目标代码生成、优化，生成 `.s` 文件）
3. 汇编（汇编器把汇编码翻译成机器码，生成 `.o` 文件）
4. 链接（连接器进行地址和空间分配、符号决议、重定位，生成 `.out` 文件）

> 现在版本 GCC 把预编译和编译合成一步，预编译编译程序 cc1、汇编器 as、连接器 ld

> MSVC 编译环境，编译器 cl、连接器 link、可执行文件查看器 dumpbin

#### 目标文件

编译器编译源代码后生成的文件叫做目标文件。目标文件从结构上讲，它是已经编译后的可执行文件格式，只是还没有经过链接的过程，其中可能有些符号或有些地址还没有被调整。

> 可执行文件（Windows 的 `.exe` 和 Linux 的 `ELF`）、动态链接库（Windows 的 `.dll` 和 Linux 的 `.so`）、静态链接库（Windows 的 `.lib` 和 Linux 的 `.a`）都是按照可执行文件格式存储（Windows 按照 PE-COFF，Linux 按照 ELF）

##### 目标文件格式

- Windows 的 PE（Portable Executable），或称为 PE-COFF，`.obj` 格式
- Linux 的 ELF（Executable Linkable Format），`.o` 格式
- Intel/Microsoft 的 OMF（Object Module Format）
- Unix 的 `a.out` 格式
- MS-DOS 的 `.COM` 格式

> PE 和 ELF 都是 COFF（Common File Format）的变种



#### 静态链接和动态链接

**静态链接** 

函数和数据被编译进⼀个⼆进制⽂件。在使⽤静态库的情况下，在编译链接可执⾏⽂件时， 链接器从库中复制这些函数和数据并把它们和应⽤程序的其它模块组合起来创建最终的可执 ⾏⽂件。 

 1、空间浪费： 因为每个可执⾏程序中对所有需要的⽬标⽂件都要有⼀份副本，所以如果多个程序对同⼀个 ⽬标⽂件都有依赖，会出现同⼀个⽬标⽂件都在内存存在多个副本； 

2、更新困难： 每当库函数的代码修改了，这个时候就需要重新进⾏编译链接形成可执⾏程序。  

3、运⾏速度快： 但是静态链接的优点就是，在可执⾏程序中已经具备了所有执⾏程序所需要的任何东西，在 执⾏的时候运⾏速度快。  

**动态链接** 

动态链接的基本思想是把程序按照模块拆分成各个相对独⽴部分，在程序运⾏时才将它们链 接在⼀起形成⼀个完整的程序，⽽不是像静态链接⼀样把所有程序模块都链接成⼀个单独的 可执⾏⽂件。  

1、共享库： 就是即使需要每个程序都依赖同⼀个库，但是该库不会像静态链接那样在内存中存在多份副 本，⽽是这多个程序在执⾏时共享同⼀份副本。 

2、更新⽅便： 更新时只需要替换原来的⽬标⽂件，⽽⽆需将所有的程序再重新链接⼀遍。当程序下⼀次运 ⾏时，新版本的⽬标⽂件会被⾃动加载到内存并且链接起来，程序就完成了升级的⽬标。 

3、性能损耗： 因为把链接推迟到了程序运⾏时，所以每次执⾏程序都需要进⾏链接，所以性能会有⼀定损 失。



### 云盘秒传的原理

上传⼤⽂件时，会对⽂件进⾏⽐对操作，这⾥的对⽐操作其实就是将我们下载的插件对要上 传的⽂件进⾏"哈希值"的计算，跟百度的"哈希值"数据库中的⽂件进⾏匹配操作。如果发现 两者的"哈希值"相同，那么，将已存在于百度数据库⾥⾯的⽂件对应的⽂件链接到我们对应 的帐号⾥，做⼀个关联就可以，其实并没有对本地⽂件进⾏上传，所以我们也就看到了秒传 的效果。 

### 线程池 

##### 什么是线程池 

1、对⽹络服务器，单位时间内必须处理数⽬巨⼤的连接请求，但是处理时间却是⽐较短 的，系统不断的启动和关闭新线程，成本⾼，会消耗系统资源，以及带来切换线程的危险， 从⽽可能导致系统资源的崩溃。这时我们可以使⽤线程池。 

2、线程池是服务器预先创建的⼀组空闲线程，它们的集合称为线程池；这些线程都是处于 阻塞状态，这些线程只占⼀点内存，不占⽤CPU。 

3、任务到来的时候，程序将⼀个任务传给线程池，线程池就会启动⼀条线程来执⾏这个任 务，执⾏结束以后，该线程并不会死亡，⽽是再次返回线程池中成为空闲状态，等待执⾏下 ⼀个任务。减少创建和销毁对象的次数，提⾼程序的运⾏效率。

![image-20230405140016504](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230405140016504.png)

##### 应⽤范围： 

1. 需要⼤量的线程来完成任务，且完成任务的时间⽐较短，不适合具有可能会长时间 运⾏(并因此阻塞其他任务)的任务。 
2. 对性能要求苛刻的应⽤，⽐如要求服务器迅速响应客户请求。 

##### 线程池线程数

CPU(计算)密集型任务: 

将线程数设置为N（CPU核⼼数）+1，⽐CPU核⼼数多出来的⼀个线程是为了防⽌线程偶发 的缺页中断，或者其它原因导致的任务暂停⽽带来的影响

IO密集型任务：  

这种任务应⽤起来，系统会⽤⼤部分的时间来处理 I/O 交互，⽽线程在处理I/O的时间段内 不会占⽤CPU来处理，这时就可以将CPU交出给其它线程使⽤。因此在I/O密集型任务的应 ⽤中，可以多配置⼀些线程，具体的计算⽅法是 2N。

##### 主进程的⼯作步骤 

1. 打开熟知端口（端口号为21），使客户进程能够连接上。  
1. 等待客户进程发出连接请求。  
1. 启动从属进程来处理客户进程发来的请求。从属进程对客户进程的请求处理完毕后 即终⽌，但从属进程在运⾏期间根据需要还可能创建其他⼀些⼦进程。  
1. 回到等待状态，继续接受其他客户进程发来的请求。主进程和从属进程的处理是并 发地进⾏。 

### 智力题

#### ⽼⿏与毒药问题 

有1000瓶⽔，其中⼀瓶有毒，只要⽼⿏喝下⼀⼩⼜毒⽔1天后就会死亡，你只有1天时间和 10只⽼⿏，如何检验出哪⼀瓶⽔有毒？ 

1. 2的每10次⽅对应10的每3次⽅，所以需要10只⽼⿏ 
2. 将1~1000号瓶⼦的编号改成⼆进制，分别喂给⼆进制表⽰中为1的位的⽼⿏，⽐如 第9瓶⽔表⽰为0000001001那么就给倒数第1只和倒数第4只⽼⿏喂第9瓶⽔ 
3. 第⼆天死亡的⽼⿏所组成的⼆进制数，即表⽰那瓶毒⽔的编号 

#### 烧绳⼦

烧⼀根绳⼦需要⼀个⼩时，现有若⼲条相同的绳⼦，问如何计时15分钟? （类似双指针） 

1. 点燃绳⼦A的⼀头，同时点燃绳⼦B的两头 
2. 绳⼦B烧完的时候绳⼦A还剩⼀半，此时点燃绳⼦A的另⼀头开始计时 
3. 15分钟绳⼦A烧完
